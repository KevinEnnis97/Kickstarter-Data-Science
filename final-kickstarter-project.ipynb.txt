{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T10:05:21.303739Z","iopub.status.idle":"2022-03-04T10:05:21.304078Z","shell.execute_reply.started":"2022-03-04T10:05:21.303898Z","shell.execute_reply":"2022-03-04T10:05:21.303921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kickstarter is a crowdfunding site. A project is only funded if the goal is met.The objective of this project was to use machine learning and data science to predict the chances of success or failure of a kickstarter project. This will give an insight into what makes a kickstarter successful and to find out what features have the biggest effect on its success rate.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset used for this was from webrobots.io, a data mining site. It contains monthly files with multiple CSV files in with data. Due to the data scraping schedule, there is a large amount of overlap creating duplicate entries. The raw data had very little missing values. It has a large amount of columns that are irrelevant to the project.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/final-kickstarter-data/final-dataset.csv')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.305202Z","iopub.status.idle":"2022-03-04T10:05:21.305512Z","shell.execute_reply.started":"2022-03-04T10:05:21.305357Z","shell.execute_reply":"2022-03-04T10:05:21.305373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Preparation\nThe data needed a lot of preparation. Of the 27 columns, 9 columns remain. Start date and end date are stored as unix time stamps. Start date and end date are converted to a number of days a campaign is running for. Name and blurb are converted to a word count. The goal is converted to a common currency using the exchange rate.\n","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.306621Z","iopub.status.idle":"2022-03-04T10:05:21.306916Z","shell.execute_reply.started":"2022-03-04T10:05:21.306762Z","shell.execute_reply":"2022-03-04T10:05:21.306777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#need to encode categories columns as wont work with strings\nfrom sklearn.preprocessing import LabelEncoder\nencodeCategories = ['category', 'city', 'country', 'state']\ndf[encodeCategories].head()\n\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.308013Z","iopub.status.idle":"2022-03-04T10:05:21.308320Z","shell.execute_reply.started":"2022-03-04T10:05:21.308153Z","shell.execute_reply":"2022-03-04T10:05:21.308169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With LGBM it had issues with working with certain datatypes and categorical data, therefore I needed to use encoding to change the values to something that can be read in by the algorithm. There was multiple ways to encode this data but i opted to use LabelEncoder from sklearn as it fit my needs better","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\n\nencoded = df[encodeCategories].apply(encoder.fit_transform)\nencoded.head()\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.309426Z","iopub.status.idle":"2022-03-04T10:05:21.309771Z","shell.execute_reply.started":"2022-03-04T10:05:21.309601Z","shell.execute_reply":"2022-03-04T10:05:21.309619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataframe is then joined with the encoded values. Once this was done it solved the issues i was having with invalid datatypes.","metadata":{}},{"cell_type":"code","source":"df = df[['blurb_word_count','duration_days', 'name_word_count', 'staff_pick', 'usd_goal']].join(encoded)\ndf.columns\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.310872Z","iopub.status.idle":"2022-03-04T10:05:21.311176Z","shell.execute_reply.started":"2022-03-04T10:05:21.311019Z","shell.execute_reply":"2022-03-04T10:05:21.311035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From  sklearn the train_test_spit module is imported. This allows me to easily split my data into 2 sets of test and training data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df[['blurb_word_count', 'category', 'city', 'country',\n       'duration_days', 'name_word_count', 'staff_pick', 'usd_goal']]\ny = df['state']","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.312021Z","iopub.status.idle":"2022-03-04T10:05:21.312329Z","shell.execute_reply.started":"2022-03-04T10:05:21.312159Z","shell.execute_reply":"2022-03-04T10:05:21.312174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is split with test size being 20 percent. After testing the training data sizes I found that 20 percent testing size produced the best results for the model.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.313951Z","iopub.status.idle":"2022-03-04T10:05:21.314284Z","shell.execute_reply.started":"2022-03-04T10:05:21.314107Z","shell.execute_reply":"2022-03-04T10:05:21.314124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nprint (y_train)\nprint (y_test)\nprint (X_train)\nprint (X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.315339Z","iopub.status.idle":"2022-03-04T10:05:21.315699Z","shell.execute_reply.started":"2022-03-04T10:05:21.315488Z","shell.execute_reply":"2022-03-04T10:05:21.315505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below is where I set up the LGBM classifier. Some parameter tuning was done to try and maximise the results. I opted to not tune the module as i was seeing very little increases in results or preformance and instead opted to test removing certain columns to see how it would affect the results. In the end I found that removing columns reduced the accuracy of the algorithm, therefore I used all the columns that where in the dataset. All of the columns that I have are important due to cleaning and preprocessing we did to only keep the most important columns that would have an affect on the final result","metadata":{}},{"cell_type":"code","source":"\n# clf = lgb.LGBMClassifier(\n# n_estimators=400,\n #   learning_rate=0.03,\n #   num_leaves=30,\n #   colsample_bytree=.8,\n #   subsample=.9,\n #   max_depth=7,\n #   reg_alpha=.1,\n #   reg_lambda=.1,\n #   min_split_gain=.01,\n #   min_child_weight=2,\n #   silent=-1,\n#    verbose=-1,)\n#clf.fit(X_train, y_train) \n#clf.fit(\n#    X_train, y_train, \n#    eval_set= [(X_train, y_train), (X_test, y_test)], \n #   eval_metric='auc', verbose=100, early_stopping_rounds=30  #30\n#)\n#\n\nclf = lgb.LGBMClassifier()\nclf.fit(X_train, y_train) \n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.317798Z","iopub.status.idle":"2022-03-04T10:05:21.318446Z","shell.execute_reply.started":"2022-03-04T10:05:21.318227Z","shell.execute_reply":"2022-03-04T10:05:21.318255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the results\ny_pred=clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.319643Z","iopub.status.idle":"2022-03-04T10:05:21.320019Z","shell.execute_reply.started":"2022-03-04T10:05:21.319841Z","shell.execute_reply":"2022-03-04T10:05:21.319861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we can see that when the algorithm runs it gives a accuracy of 81 percent and a very similar result on the testing data. This is in my opinion a good accuracy at predicting success rate ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_pred, y_test)\nprint('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.320935Z","iopub.status.idle":"2022-03-04T10:05:21.321265Z","shell.execute_reply.started":"2022-03-04T10:05:21.321084Z","shell.execute_reply":"2022-03-04T10:05:21.321108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"y_pred_train = clf.predict(X_train)\nprint('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.322289Z","iopub.status.idle":"2022-03-04T10:05:21.322659Z","shell.execute_reply.started":"2022-03-04T10:05:21.322447Z","shell.execute_reply":"2022-03-04T10:05:21.322470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below i uses sklearn to produce a classification report. This report shows how well it classified the data. It shows me that it is more sucessful at predicting failures rather than sucesses but still has a good f1 score in my opinion ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.324471Z","iopub.status.idle":"2022-03-04T10:05:21.326010Z","shell.execute_reply.started":"2022-03-04T10:05:21.325804Z","shell.execute_reply":"2022-03-04T10:05:21.325826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below i used the feature importance chart to show that category is the most important attribute when trying to predict success with the algorithm while staff pick is lower priority. This could be due to the fact that it is quiet uncommon for a project to get staff pick even though projects that are staff pick are 90 percent chance to be sucessfull","metadata":{}},{"cell_type":"code","source":"lgb.plot_importance(clf)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.326715Z","iopub.status.idle":"2022-03-04T10:05:21.327108Z","shell.execute_reply.started":"2022-03-04T10:05:21.326888Z","shell.execute_reply":"2022-03-04T10:05:21.326910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below i have displayed a confusion matrix. It shows that the algorithm is much more successful at getting true positives rather than true negatives. False positives and false negatives are close in value to eachother but still a low number in comparison to the true values. It is only slightly worse at false potitives compared to false negatives","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint('Confusion matrix\\n\\n', cm)\nprint('\\nTrue Positives(TP) = ', cm[0,0])\nprint('\\nTrue Negatives(TN) = ', cm[1,1])\nprint('\\nFalse Positives(FP) = ', cm[0,1])\nprint('\\nFalse Negatives(FN) = ', cm[1,0])","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:05:21.328677Z","iopub.status.idle":"2022-03-04T10:05:21.329115Z","shell.execute_reply.started":"2022-03-04T10:05:21.328884Z","shell.execute_reply":"2022-03-04T10:05:21.328907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:45:43.568243Z","iopub.execute_input":"2022-02-18T17:45:43.568593Z","iopub.status.idle":"2022-02-18T17:45:43.661237Z","shell.execute_reply.started":"2022-02-18T17:45:43.568496Z","shell.execute_reply":"2022-02-18T17:45:43.660026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}